apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-toolkit
  namespace: ai-toolkit
  labels:
    app: ai-toolkit
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-toolkit
  template:
    metadata:
      labels:
        app: ai-toolkit
    spec:
      # GPU 支持
      # 如果集群使用 NVIDIA GPU Runtime Class，取消下面的注释
      # runtimeClassName: nvidia
      # 或者使用 nodeSelector 选择 GPU 节点
      # nodeSelector:
      #   accelerator: nvidia-tesla-k80  # 根据你的 GPU 节点标签调整
      containers:
      - name: ai-toolkit
        image: ostris/aitoolkit:latest
        imagePullPolicy: Always
        ports:
        - name: http
          containerPort: 8675
          protocol: TCP
        env:
        - name: AI_TOOLKIT_AUTH
          valueFrom:
            secretKeyRef:
              name: ai-toolkit-secret
              key: auth-token
        - name: NODE_ENV
          value: "production"
        - name: TZ
          value: "UTC"
        resources:
          limits:
            # 根据实际 GPU 数量调整，如果需要使用所有 GPU，设置为节点上的 GPU 数量
            nvidia.com/gpu: 1  # 或者设置为具体数量，如 2, 4, 8 等
          requests:
            nvidia.com/gpu: 1
        volumeMounts:
        # HuggingFace 缓存
        - name: storage
          mountPath: /root/.cache/huggingface/hub
          subPath: huggingface-cache
        # 数据库文件
        - name: storage
          mountPath: /app/ai-toolkit/aitk_db.db
          subPath: aitk_db.db
        # 数据集目录
        - name: storage
          mountPath: /app/ai-toolkit/datasets
          subPath: datasets
        # 输出目录
        - name: storage
          mountPath: /app/ai-toolkit/output
          subPath: output
        # 配置目录
        - name: storage
          mountPath: /app/ai-toolkit/config
          subPath: config
        # 共享内存 60GB
        - name: shm
          mountPath: /dev/shm
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: ai-toolkit-storage
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 60Gi
      restartPolicy: Always
